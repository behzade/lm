#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "openai",
#     "rich",
#     "pyperclip",
#     "arabic_reshaper",
#     "python-bidi",
#     "ddgs",
#     "typer[all]",
#     "readchar",
# ]
# ///

import sys
import json
import os
import subprocess
import datetime
from typing import Optional, List, Dict, Any
from pathlib import Path

import openai
import pyperclip
import typer
from typer import Abort
from typing_extensions import Annotated
from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from rich.spinner import Spinner

import arabic_reshaper
from bidi.algorithm import get_display
from ddgs import DDGS

# --- Constants ---
DEFAULT_LOCAL_API_URL = "http://localhost:1234/v1"
DEFAULT_SYSTEM_PROMPT = "You are a helpful assistant inside a terminal. Keep your responses short and concise. Format your output as markdown."


class StreamingToolCallBuilder:
    """Reconstructs tool calls from a streaming API response."""

    def __init__(self):
        self._tool_calls: List[Dict[str, Any]] = []

    def accumulate(self, delta: Any):
        if not delta or not delta.tool_calls:
            return

        for tc in delta.tool_calls:
            if len(self._tool_calls) <= tc.index:
                self._tool_calls.append(
                    {
                        "id": "",
                        "type": "function",
                        "function": {"name": "", "arguments": ""},
                    }
                )

            call = self._tool_calls[tc.index]
            call["id"] += tc.id or ""
            if tc.function:
                call["function"]["name"] += tc.function.name or ""
                call["function"]["arguments"] += tc.function.arguments or ""

    @property
    def tool_calls(self) -> List[Dict[str, Any]]:
        return self._tool_calls


# --- Tool Definitions and Handlers ---


def perform_web_search(query: str, num_results: int = 10) -> str:
    """Performs a web search using DuckDuckGo and returns formatted results."""
    try:
        results = DDGS().text(query, max_results=num_results)
        if not results:
            return "No results found for the query."
        formatted_results = [
            f"**Source {i + 1}: {r['title']}**\nSnippet: {r['body']}\nURL: {r['href']}"
            for i, r in enumerate(results)
        ]
        return "\n\n---\n\n".join(formatted_results)
    except Exception as e:
        return f"An error occurred during web search: {e}"


AVAILABLE_TOOLS: Dict[str, Dict[str, Any]] = {
    "web_search": {
        "definition": {
            "type": "function",
            "function": {
                "name": "web_search",
                "description": "Performs a web search to get up-to-date information or context.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "The search query."}
                    },
                    "required": ["query"],
                },
            },
        },
        "function": perform_web_search,
    },
}


class ConfigManager:
    """Handles loading of the configuration file."""

    def __init__(self, config_path: Path):
        self.config_file = config_path / "config.json"
        self.config = {}
        self.load()

    def load(self):
        try:
            if self.config_file.is_file():
                self.config = json.loads(self.config_file.read_text())
            else:
                self.config = {
                    "model": "local-model",
                    "api_url": DEFAULT_LOCAL_API_URL,
                    "api_key_var": "sk-dummy",
                }
                self.save()
        except (json.JSONDecodeError, IOError) as e:
            Console().print(
                f"[bold yellow]Warning:[/bold yellow] Could not load config file: {e}. Using defaults."
            )
            self.config = {
                "model": "local-model",
                "api_url": DEFAULT_LOCAL_API_URL,
                "api_key_var": "sk-dummy",
            }

    def save(self):
        self.config_file.parent.mkdir(parents=True, exist_ok=True)
        self.config_file.write_text(json.dumps(self.config, indent=2))

    def get(self, key: str, default: Any = None) -> Any:
        return self.config.get(key, default)


def get_config_path() -> Path:
    xdg_config_home = os.getenv("XDG_CONFIG_HOME")
    if xdg_config_home:
        return Path(xdg_config_home) / "lm"
    return Path.home() / ".config" / "lm"


# --- Core Functions ---
def fix_rtl_output(text: str) -> str:
    """Reshapes and reorders text for correct display in terminals that don't support RTL."""
    reshaped_text = arabic_reshaper.reshape(text)
    return get_display(reshaped_text)


def edit_agent_profile(console: Console, agent_name: str):
    prompt_path = get_config_path() / f"{agent_name}.md"
    prompt_path.parent.mkdir(parents=True, exist_ok=True)
    editor = os.getenv("EDITOR", "nano")
    console.print(
        f"Opening agent '[cyan]{agent_name}[/cyan]' with [yellow]{editor}[/yellow]..."
    )
    try:
        subprocess.run([editor, str(prompt_path)], check=True)
    except (FileNotFoundError, subprocess.CalledProcessError) as e:
        console.print(f"[bold red]Error:[/bold red] {e}")
        raise typer.Exit(code=1)


def load_system_prompt(console: Console, agent_name: Optional[str]) -> str:
    if not agent_name:
        return DEFAULT_SYSTEM_PROMPT
    prompt_path = get_config_path() / f"{agent_name}.md"
    if not prompt_path.is_file():
        console.print(
            f"[bold red]Error:[/bold red] Agent not found at '[yellow]{prompt_path}[/yellow]'"
        )
        raise typer.Exit(code=1)
    try:
        system_prompt = prompt_path.read_text(encoding="utf-8")
        today = datetime.date.today()
        return f"{system_prompt}\n\n**Today's date:** {today}"
    except IOError as e:
        console.print(
            f"[bold red]Error reading agent profile '{prompt_path}':[/bold red] {e}"
        )
        raise typer.Exit(code=1)


def get_input(prompt_arg: Optional[str]) -> str:
    """Gets input from the prompt argument and/or stdin, combining them if both are present."""
    prompt_parts = []

    if prompt_arg:
        prompt_parts.append(prompt_arg)

    if not sys.stdin.isatty():
        stdin_content = sys.stdin.read().strip()
        if stdin_content:
            prompt_parts.append(stdin_content)

    return "\n\n".join(prompt_parts)


def build_context(
    console: Console,
    errorConsole: Console,
    from_clipboard: bool,
    files: Optional[List[str]],
) -> str:
    context_parts = []
    if from_clipboard:
        try:
            clipboard_content = pyperclip.paste()
            if clipboard_content:
                context_parts.append(
                    f"--- Content from clipboard ---\n{clipboard_content}"
                )
        except pyperclip.PyperclipException as e:
            errorConsole.print(f"[bold red]Clipboard error:[/bold red] {e}")
    if files:
        for file_path in files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    context_parts.append(
                        f"--- Content from file: {file_path} ---\n{f.read()}"
                    )
            except (IOError, FileNotFoundError) as e:
                errorConsole.print(
                    f"[bold red]Error reading file '{file_path}':[/bold red] {e}"
                )
                raise typer.Exit(code=1)
    return "\n\n".join(context_parts)


# --- Main Execution Logic ---
app = typer.Typer(
    add_completion=False, help="A command-line chatbot.", no_args_is_help=False
)


@app.callback(invoke_without_command=True)
def main(
    prompt: Annotated[
        Optional[str],
        typer.Argument(help="The user prompt. Reads from stdin if not provided."),
    ] = None,
    file: Annotated[
        Optional[List[str]],
        typer.Option("-f", "--file", help="Path to a file to add to the context."),
    ] = None,
    from_clipboard: Annotated[
        bool,
        typer.Option(
            "-c", "--from-clipboard", help="Add clipboard content to the context."
        ),
    ] = False,
    agent: Annotated[
        Optional[str],
        typer.Option("-a", "--agent", help="Name of the agent profile to load."),
    ] = None,
    edit_agent: Annotated[
        Optional[str],
        typer.Option(
            "-e",
            "--edit-agent",
            metavar="AGENT_NAME",
            help="Create or edit an agent profile.",
        ),
    ] = None,
    model: Annotated[
        Optional[str],
        typer.Option("-m", "--model", help="Override the configured model."),
    ] = None,
    api_url: Annotated[
        Optional[str],
        typer.Option(
            "-u", "--api-url", help="Override the configured API endpoint URL."
        ),
    ] = None,
    max_tool_turns: Annotated[
        int,
        typer.Option(
            "-l", "--max-tool-turns", help="Maximum number of tool-use turns."
        ),
    ] = 5,
    temperature: Annotated[
        float, typer.Option("-t", "--temperature", help="The sampling temperature.")
    ] = 0.7,
    top_p: Annotated[
        float, typer.Option("-p", "--top-p", help="The nucleus sampling probability.")
    ] = 0.95,
):
    console = Console()
    errorConsole = Console(stderr=True)
    total_in_tokens, total_out_tokens = 0, 0
    is_interactive = sys.stdout.isatty()

    if edit_agent:
        edit_agent_profile(console, edit_agent)
        raise typer.Exit()

    config_manager = ConfigManager(get_config_path())

    try:
        base_url = api_url or config_manager.get("api_url")
        api_model = model or config_manager.get("model")
        api_key_var = config_manager.get("api_key_var", "sk-dummy")

        api_key = "sk-dummy"
        if api_key_var != "sk-dummy":
            api_key = os.getenv(api_key_var)

        if not api_key:
            console.print(
                f"[bold red]Error:[/bold red] Environment variable '{api_key_var}' is not set and is required."
            )
            raise typer.Exit(code=1)

        client = openai.OpenAI(base_url=base_url, api_key=api_key)
        system_prompt = load_system_prompt(console, agent)
        context_str = build_context(console, errorConsole, from_clipboard, file)
        user_prompt = get_input(prompt)
        final_user_message = (
            f"{context_str}\n\n---\n\n{user_prompt}" if context_str else user_prompt
        )

        if not final_user_message:
            errorConsole.print(
                "[bold red]Error:[/bold red] Prompt is empty.",
            )
            raise typer.Exit(code=1)

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": final_user_message},
        ]
        tools = (
            [t["definition"] for t in AVAILABLE_TOOLS.values()]
            if AVAILABLE_TOOLS
            else None
        )

        for i in range(max_tool_turns):
            api_kwargs = {
                "model": api_model,
                "messages": messages,
                "temperature": temperature,
                "top_p": top_p,
                "stream": True,
            }
            if tools:
                api_kwargs["tools"] = tools
                api_kwargs["tool_choice"] = "auto"
                if i == max_tool_turns - 1:
                    api_kwargs["tool_choice"] = "none"
            
            # --- START: FIXED STREAMING LOGIC ---
            stream = client.chat.completions.create(**api_kwargs)
            full_content = ""
            tool_call_builder = StreamingToolCallBuilder()

            if is_interactive:
                with Live(
                    Spinner("dots", text=f" [grey]{api_model}[/grey]..."),
                    console=console,
                    auto_refresh=True,
                    vertical_overflow="visible",
                ) as live:
                    for chunk in stream:
                        if chunk.usage:
                            total_in_tokens += getattr(chunk.usage, "prompt_tokens", 0)
                            total_out_tokens += getattr(
                                chunk.usage, "completion_tokens", 0
                            )

                        delta = chunk.choices[0].delta
                        full_content += delta.content or ""
                        tool_call_builder.accumulate(delta)
                        
                        # Update the live display, replacing the spinner on the first run
                        live.update(Markdown(fix_rtl_output(full_content)))
            else:
                # Non-interactive: just accumulate the content without live rendering
                for chunk in stream:
                    if chunk.usage:
                        total_in_tokens += getattr(chunk.usage, "prompt_tokens", 0)
                        total_out_tokens += getattr(
                            chunk.usage, "completion_tokens", 0
                        )

                    delta = chunk.choices[0].delta
                    full_content += delta.content or ""
                    tool_call_builder.accumulate(delta)
            # --- END: FIXED STREAMING LOGIC ---

            assistant_tool_calls = tool_call_builder.tool_calls
            assistant_message = {
                "role": "assistant",
                "content": full_content or None,
                "tool_calls": assistant_tool_calls if assistant_tool_calls else None,
            }
            messages.append(assistant_message)

            if not assistant_tool_calls:
                if not is_interactive:
                    print(full_content, end="")
                break

            errorConsole.print("[dim]Tool call(s) requested...[/dim]")
            for tool_call in assistant_tool_calls:
                function_name = tool_call["function"]["name"]
                tool_output = f"Error: Unknown tool '{function_name}'."
                try:
                    args_dict = json.loads(tool_call["function"]["arguments"])
                    tool_info = AVAILABLE_TOOLS.get(function_name)

                    if not tool_info:
                        raise ValueError(
                            f"Tool '{function_name}' not found in AVAILABLE_TOOLS."
                        )

                    if tool_func := tool_info.get("function"):
                        errorConsole.print(
                            f"[dim]Performing: [cyan]{function_name}[/cyan] with args: {args_dict}[/dim]",
                        )
                        tool_output = tool_func(**args_dict)
                    else:
                        raise ValueError(
                            f"No valid function for tool '{function_name}'."
                        )

                except json.JSONDecodeError as e:
                    tool_output = f"Error decoding tool arguments: {e}"
                except (TypeError, ValueError, Abort) as e:
                    tool_output = f"Error during tool execution: {e}"

                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "content": tool_output,
                    }
                )

        if (total_in_tokens + total_out_tokens) > 0 and is_interactive:
            console.print(f"\n[dim]->:{total_in_tokens} <-:{total_out_tokens}[/dim]")

    except KeyboardInterrupt:
        errorConsole.print("\n[yellow]Operation cancelled by user.[/yellow]")
        raise typer.Exit(code=130)
    except openai.APIError as e:
        errorConsole.print(f"[bold red]API Error:[/bold red] {e}")
        raise typer.Exit(code=1)


if __name__ == "__main__":
    app()
